# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TECpMPgIwaAQcnmhFZL-Ll53zhv8S7j6
"""

# Commented out IPython magic to ensure Python compatibility.
# Clone Real-ESRGAN and enter the Real-ESRGAN
!git clone https://github.com/xinntao/Real-ESRGAN.git
# %cd Real-ESRGAN
# Set up the environment
!pip install basicsr
!pip install facexlib
!pip install gfpgan
!pip install ffmpeg-python
!pip install -r requirements.txt
!python setup.py develop

file_path = "/usr/local/lib/python3.10/dist-packages/basicsr/data/degradations.py"

# Read the file content
with open(file_path, "r") as file:
    content = file.read()

# Replace the incorrect import
content = content.replace(
    "from torchvision.transforms.functional_tensor import rgb_to_grayscale",
    "from torchvision.transforms.functional import rgb_to_grayscale"
)

# Write the updated content back to the file
with open(file_path, "w") as file:
    file.write(content)

print("File updated successfully!")

from IPython.display import HTML
from base64 import b64encode

def show_video(video_path, video_width = 600):

  video_file = open(video_path, "r+b").read()

  video_url = f"data:video/mp4;base64,{b64encode(video_file).decode()}"
  return HTML(f"""<video width={video_width} controls><source src="{video_url}"></video>""")

# input video
show_video('/content/Real-ESRGAN/inputs/video/onepiece_demo.mp4')

!ffmpeg -i /content/Real-ESRGAN/inputs/video/onepiece_demo.mp4 -c:v libx264 -preset slow -crf 22 -c:a copy /content/Real-ESRGAN/inputs/video/converted_demo.mp4

from IPython.display import HTML
from base64 import b64encode

def show_video(video_path, video_width = 600):

  video_file = open(video_path, "r+b").read()

  video_url = f"data:video/mp4;base64,{b64encode(video_file).decode()}"
  return HTML(f"""<video width={video_width} controls><source src="{video_url}"></video>""")

# input video
show_video('/content/Real-ESRGAN/results/output_video.mp4')







!pip install flask

from pyngrok import ngrok


public_url = ngrok.connect(5000)
print(f"ngrok is running at: {public_url}")

!ngrok config add-authtoken 2pFUN06zujuxy8XBkltR2xQjziT_2nYTaEbjpGhih9PzFWSgu

!pip install pyngrok

!ls /content/Real-ESRGAN/inference_realesrgan.py

from flask import Flask, request, jsonify, send_from_directory
import os
import shutil
import subprocess
from werkzeug.utils import secure_filename
from pyngrok import ngrok

ngrok.set_auth_token("2pFUN06zujuxy8XBkltR2xQjziT_2nYTaEbjpGhih9PzFWSgu")

app = Flask(__name__)

# Define paths
UPLOAD_FOLDER = '/content/Real-ESRGAN/inputs/video'
FRAME_FOLDER = '/content/Real-ESRGAN/inputs/video_frames'
RESULTS_FOLDER = '/content/Real-ESRGAN/results'
MODEL_FOLDER = '/content/Real-ESRGAN'
ENHANCED_FRAMES_FOLDER = '/content/Real-ESRGAN/results_frames'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(FRAME_FOLDER, exist_ok=True)
os.makedirs(RESULTS_FOLDER, exist_ok=True)
os.makedirs(ENHANCED_FRAMES_FOLDER, exist_ok=True)

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['RESULTS_FOLDER'] = RESULTS_FOLDER

# Allowed extensions
ALLOWED_EXTENSIONS = {'mp4'}

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@app.route('/upload', methods=['POST'])
def upload_video():
    if 'file' not in request.files:
        return jsonify({'error': 'No file provided'}), 400

    file = request.files['file']
    if file and allowed_file(file.filename):
        filename = secure_filename(file.filename)
        upload_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(upload_path)

        # Process the video
        output_video_path = process_video(upload_path)
        if output_video_path:
            return jsonify({'message': 'Video processed successfully', 'output_path': f'/results/{os.path.basename(output_video_path)}'}), 200
        else:
            return jsonify({'error': 'Error processing video'}), 500
    else:
        return jsonify({'error': 'Invalid file type'}), 400

@app.route('/results/<filename>', methods=['GET'])
def download_result(filename):
    return send_from_directory(app.config['RESULTS_FOLDER'], filename)

def process_video(video_path):
    # Step 1: Extract frames
    frame_output_path = os.path.join(FRAME_FOLDER, 'frame_%04d.png')
    ffmpeg_extract_cmd = [
        'ffmpeg', '-i', video_path, frame_output_path
    ]
    subprocess.run(ffmpeg_extract_cmd, check=True)

    # Step 2: Enhance frames using Real-ESRGAN
    inference_cmd = [
        'python', f'{MODEL_FOLDER}/inference_realesrgan.py',
        '-i', FRAME_FOLDER,
        '-o', ENHANCED_FRAMES_FOLDER,
        '-s', '2',
        '--suffix', 'outx2'
    ]
    subprocess.run(inference_cmd, check=True)

    # Step 3: Reconstruct video from enhanced frames
    enhanced_video_path = os.path.join(RESULTS_FOLDER, 'enhanced_video.mp4')
    ffmpeg_reconstruct_cmd = [
        'ffmpeg', '-framerate', '30', '-i', f'{ENHANCED_FRAMES_FOLDER}/frame_%04d_outx2.png',
        '-c:v', 'libx264', '-pix_fmt', 'yuv420p', enhanced_video_path
    ]
    subprocess.run(ffmpeg_reconstruct_cmd, check=True)

    # Clean up frames (optional)
    shutil.rmtree(FRAME_FOLDER)
    os.makedirs(FRAME_FOLDER, exist_ok=True)
    shutil.rmtree(ENHANCED_FRAMES_FOLDER)
    os.makedirs(ENHANCED_FRAMES_FOLDER, exist_ok=True)

    return enhanced_video_path

if __name__ == '__main__':
    public_url = ngrok.connect(5000)  # Connect to the same port as Flask
    print(f"Public URL: {public_url}")
    app.run(debug=True, host='0.0.0.0', port=5000)

!ngrok http 5000









!pip install opencv-python-headless

!pip install -r /content/Real-ESRGAN/requirements.txt

import cv2

cap = cv2.VideoCapture('/content/Real-ESRGAN/inputs/video/onepiece_demo.mp4')
if not cap.isOpened():
    print("Error: Cannot open video.")
else:
    success, frame = cap.read()
    while success:
        print("Frame shape:", frame.shape)  # Debug to check frames
        success, frame = cap.read()
cap.release()
!mkdir -p /content/Real-ESRGAN/inputs/video_frames
!ffmpeg -i /content/Real-ESRGAN/inputs/video/onepiece_demo.mp4 /content/Real-ESRGAN/inputs/video_frames/frame_%04d.png
!python inference_realesrgan.py -i /content/Real-ESRGAN/inputs/video_frames/ -o /content/Real-ESRGAN/results_frames/ -s 2 --suffix outx2
!ffmpeg -framerate 30 -i /content/Real-ESRGAN/results_frames/frame_%04d_outx2.png -c:v libx264 -pix_fmt yuv420p /content/Real-ESRGAN/results/output_video.mp4

from IPython.display import Video
Video('/content/Real-ESRGAN/results/output_video.mp4', embed=True)

!python inference_realesrgan.py -i /content/Real-ESRGAN/inputs/video/converted_demo.mp4 -o results -s 2 --suffix outx2



